# Keyboard generation using RL

## Team

- Vsevolod Klyushev / <v.klyushev@innopolis.university>
- Dmitry Beresnev / <d.beresnev@innopolis.university>
- Ivan Inchin / <i.inchin@innopolis.university>

## Introduction

Our task is to find more optimal keyboard layout for code writing. Existing keyboard layouts were created for writing literature text. However, the code-writing process has its features. One of the most significant changes involves the frequent incorporation of special characters, as well as the increased usage of specific words, phrases, and expressions.

A unique keyboard layout might be generated by 26! ways. The computer performs about $10^8$ simple operations over 1 second. It could be assumed that the metric calculation for an arbitrary keyboard layout requires just one simple operation, then it would take more than 127 billion years to check every possible combination. Therefore random generation is not good way to solve such problem.

## Requirements

Code was tested on Windows 10, Python 3.10 and CUDA 11.8.

All the requirement packages are listed in the file `requirements.txt`. In case you use the `pipenv` package, there is also `Pipfile` in the root of the project.

## Before start

Install all the packages from _requirements.txt_ using `pip install -r requirements.txt` or using **pipenv** `pipenv install`.

Optionally, you can run `bash setup_precommit.sh` to setup pre-commit hook for GitHub for code formatting using [ruff](https://docs.astral.sh/ruff/).

We also highly recommend to read reports in corresponding `reports` folder to fully understand context and purpose of some files and folders.

## Repository structure

```text
├── README.md       # The top-level README
│
├── data
│   ├── figures     # Plots and other visualized data
│   ├── generated   # Data generated by models and other scripts
|   |   ├── bart.csv
|   |   ├── custom_transformer.csv
|   |   └── metrics.csv   # Metrics for both models
|   |
│   ├── interim     # Intermediate data that has been transformed
|   |   └── validated # Folder with data in csv format
|   |
│   └── raw         # The original, immutable data. Collected via src/make_dataset.py script
|       ├── encoded_programs.csv
|       └── raw_programs.csv
│
├── models          # Trained and serialized models, final checkpoints
│   └── policy # torch model weights
│
├── notebooks       #  Jupyter notebooks
│   ├── ActorCritic.ipynb
│   └── Baseline.ipynb
│
├── reports                 # Generated analysis as HTML, PDF, LaTeX, etc.
│   └── Report.pdf           # Main assignment report
│
├── requirements.txt  # The requirements file for reproducing the analysis environment
│                      generated with pip freeze › requirements. txt'
|
└── src                 # Source code for use in this assignment
|    │
|    ├── data            # Scripts to download or generate data
|    │   └── make_dataset.py
|    │
|    ├── models          # Scripts to train models and then use trained models to make |predictions
|    │   ├── baseline.py
|    │   └── train.py
|    │
|    └── keyboard.py # Scripts with environment
|
├── Pipfile         # File with dependencies for pipenv
├── pyproject.toml  # Formatter and linter settings
└── setup_precommit.sh  # Script for creating pre-commit GitHub hook
```

## Basic usage

This section describes how to use scripts from `src/` folder.

For all scripts help messages are available with `-h` flag. For example, `python ./src/data/make_dataset.py -h` explains all the available flags and their purpose. Generally, for all scripts two modes are available: verbose and non-verbose. By default verbose mode is active, and to run the script in silent mode you need the `--no-verbose` flag.

You can run `python ./src/models/baseline.py` to randomly generate some number of keyboard layouts, estimate them and plot graphs.
Also, you can run `python ./src/models/train.py` in order to train Policy NN, estimate its performance, save model and plot graphs.

## Contacts

In case of any questions you can contact us via emails <v.klyushev@innopolis.university>/<d.beresnev@innopolis.university>/<i.inchin@innopolis.university> or Telegram **@Kiaver**/**@d.flip.floppa**/**@extrabution**
